{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21364fd",
   "metadata": {},
   "source": [
    "# Titanic - Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc50a4",
   "metadata": {},
   "source": [
    "## Trainning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397ff08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Acc: 0.8436 | F1: 0.8133\n",
      "Fold 2 - Acc: 0.8146 | F1: 0.7402\n",
      "Fold 3 - Acc: 0.8820 | F1: 0.8467\n",
      "Fold 4 - Acc: 0.8146 | F1: 0.7317\n",
      "Fold 5 - Acc: 0.8315 | F1: 0.7656\n",
      "\n",
      "==== Mean metrics ====\n",
      "Accuracy: 0.8373\n",
      "Precision: 0.8038\n",
      "Recall: 0.7580\n",
      "F1-score: 0.7795\n",
      "Std (Accuracy): 0.0249\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tuningModel import tune_logistic_regression\n",
    "# === Load dá»¯ liá»‡u ===\n",
    "path_dir = join(\"..\", \"..\", \"..\")\n",
    "input_dir = join(path_dir, \"data\", \"feature_engineered\", \"nameMiner\")\n",
    "\n",
    "df_train = pd.read_csv(join(input_dir, \"nameMiner_engineered_train.csv\"))\n",
    "df_test = pd.read_csv(join(input_dir, \"nameMiner_engineered_test.csv\"))\n",
    "\n",
    "X = df_train.drop(['Survived'], axis=1)\n",
    "y = df_train['Survived']\n",
    "# === Chuáº©n hÃ³a dá»¯ liá»‡u (giÃºp Logistic Regression há»™i tá»¥ á»•n Ä‘á»‹nh hÆ¡n) ===\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(df_test.drop(columns=['Survived'], errors='ignore'))\n",
    "\n",
    "# best_model, result_df = tune_logistic_regression(X,y)\n",
    "# === KFold ===\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "\n",
    "fold_index = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # === MÃ´ hÃ¬nh Logistic Regression ===\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver='lbfgs',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold_index} - Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
    "    fold_index += 1\n",
    "\n",
    "# === Mean & Std ===\n",
    "mean_acc = np.mean(accuracies)\n",
    "mean_prec = np.mean(precisions)\n",
    "mean_rec = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1s)\n",
    "std_acc = np.std(accuracies)\n",
    "\n",
    "print(\"\\n==== Mean metrics ====\")\n",
    "print(f\"Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Precision: {mean_prec:.4f}\")\n",
    "print(f\"Recall: {mean_rec:.4f}\")\n",
    "print(f\"F1-score: {mean_f1:.4f}\")\n",
    "print(f\"Std (Accuracy): {std_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27cf19",
   "metadata": {},
   "source": [
    "## Save model into logger and dump model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26d699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged experiment to ..\\..\\..\\log\\experiment_log.csv\n",
      "âœ… Model saved to ..\\..\\..\\notebook\\model\\logistic_regression\\Model Pickles\\lr_nameMiner.pkl\n",
      "ðŸ“¤ Submission file saved to ..\\..\\..\\notebook\\model\\logistic_regression\\submissions\\submission_lr_nameMiner.csv\n"
     ]
    }
   ],
   "source": [
    "# === Import log_experiment ===\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "from log.experiment_logger import log_experiment\n",
    "\n",
    "# === Ghi log káº¿t quáº£ vÃ o CSV ===\n",
    "log_path = join(path_dir, \"log\", \"experiment_log.csv\")\n",
    "log_experiment(\n",
    "    output_path=log_path,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    feature_name=\"nameMiner_engineered\",\n",
    "    params= model.get_params(),\n",
    "    kfold=5,\n",
    "    f1=mean_f1,\n",
    "    acc=mean_acc,\n",
    "    rec=mean_rec,\n",
    "    prec=mean_prec,\n",
    "    std=std_acc,\n",
    "    author=\"Thang\"\n",
    ")\n",
    "\n",
    "# === Huáº¥n luyá»‡n láº¡i trÃªn toÃ n bá»™ dá»¯ liá»‡u train ===\n",
    "final_model = model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# === LÆ°u model ===\n",
    "model_dir = join(path_dir, \"notebook\", \"model\", \"logistic_regression\", \"Model Pickles\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = join(model_dir, \"lr_nameMiner.pkl\")\n",
    "joblib.dump((final_model, scaler), model_path)  # lÆ°u luÃ´n scaler Ä‘á»ƒ predict sau\n",
    "print(f\"âœ… Model saved to {model_path}\")\n",
    "df_original = pd.read_csv(join(path_dir,\"data\",\"raw\",\"test.csv\"))\n",
    "passenger_ids = df_original[\"PassengerId\"]\n",
    "# === Táº¡o file submission ===\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,  # pháº£i cÃ³ trong test\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "\n",
    "sub_dir = join(path_dir, \"notebook\", \"model\", \"logistic_regression\", \"submissions\")\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "submission_path = join(sub_dir, \"submission_lr_nameMiner.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"ðŸ“¤ Submission file saved to {submission_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba212e9",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
