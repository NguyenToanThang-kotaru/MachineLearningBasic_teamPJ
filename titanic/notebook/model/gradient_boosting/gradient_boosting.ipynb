{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21364fd",
   "metadata": {},
   "source": [
    "# Titanic - Gradient_boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc50a4",
   "metadata": {},
   "source": [
    "## Trainning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397ff08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "\n",
      " Best Score (accuracy): 0.8485\n",
      " Best Params: {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Fold 1 - Acc: 0.8380 | F1: 0.8027\n",
      "Fold 2 - Acc: 0.8034 | F1: 0.7059\n",
      "Fold 3 - Acc: 0.8539 | F1: 0.8088\n",
      "Fold 4 - Acc: 0.7753 | F1: 0.6825\n",
      "Fold 5 - Acc: 0.8427 | F1: 0.7879\n",
      "\n",
      "==== Mean metrics ====\n",
      "Accuracy: 0.8227\n",
      "Precision: 0.7884\n",
      "Recall: 0.7323\n",
      "F1-score: 0.7576\n",
      "Std (Accuracy): 0.0291\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from tuningModel import tune_gradient_boosting\n",
    "# === Load d·ªØ li·ªáu ===\n",
    "path_dir = join(\"..\", \"..\", \"..\")\n",
    "input_dir = join(path_dir, \"data\", \"feature_engineered\", \"scaledData\")\n",
    "\n",
    "df_train = pd.read_csv(join(input_dir, \"scaledData_engineered_train.csv\"))\n",
    "df_test = pd.read_csv(join(input_dir, \"scaledData_engineered_test.csv\"))\n",
    "\n",
    "X = df_train.drop(['Survived'], axis=1)\n",
    "y = df_train['Survived']\n",
    "best_model, results_df = tune_gradient_boosting(X,y)\n",
    "# === KFold ===\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies, precisions, recalls, f1s = [], [], [], []\n",
    "\n",
    "fold_index = 1\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # === M√¥ h√¨nh Gradient Boosting ===\n",
    "    model = best_model\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # === T√≠nh metric ===\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold_index} - Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
    "    fold_index += 1\n",
    "\n",
    "# === Mean v√† Std ===\n",
    "mean_acc = np.mean(accuracies)\n",
    "mean_prec = np.mean(precisions)\n",
    "mean_rec = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1s)\n",
    "std_acc = np.std(accuracies)\n",
    "\n",
    "print(\"\\n==== Mean metrics ====\")\n",
    "print(f\"Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Precision: {mean_prec:.4f}\")\n",
    "print(f\"Recall: {mean_rec:.4f}\")\n",
    "print(f\"F1-score: {mean_f1:.4f}\")\n",
    "print(f\"Std (Accuracy): {std_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27cf19",
   "metadata": {},
   "source": [
    "## Save model into logger and dump model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged experiment to ..\\..\\..\\log\\experiment_log.csv\n",
      "‚úÖ Model saved to ..\\..\\..\\notebook\\model\\gradient_boosting\\Model Pickles\\gb_scaledData_tuned.pkl\n",
      "üì§ Submission file saved to ..\\..\\..\\notebook\\model\\gradient_boosting\\submissions\\submission_gb_scaledData_tuned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# === Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import log_experiment ===\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "from log.experiment_logger import log_experiment\n",
    "\n",
    "# === Ghi log k·∫øt qu·∫£ v√†o CSV ===\n",
    "log_path = join(path_dir, \"log\", \"experiment_log.csv\")\n",
    "log_experiment(\n",
    "    output_path=log_path,\n",
    "    model_name=\"GradientBoostingClassifier\",\n",
    "    feature_name=\"scaledData_engineered\",\n",
    "    params=best_model.get_params(),\n",
    "    kfold=5,\n",
    "    f1=mean_f1,\n",
    "    acc=mean_acc,\n",
    "    rec=mean_rec,\n",
    "    prec=mean_prec,\n",
    "    std=std_acc,\n",
    "    author=\"Thang\"\n",
    ")\n",
    "\n",
    "# === Hu·∫•n luy·ªán l·∫°i tr√™n to√†n b·ªô d·ªØ li·ªáu train ===\n",
    "final_model = best_model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# === Dump model ra .pkl ===\n",
    "model_dir = join(path_dir, \"notebook\", \"model\", \"gradient_boosting\", \"Model Pickles\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = join(model_dir, \"gb_scaledData_tuned.pkl\")\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"‚úÖ Model saved to {model_path}\")\n",
    "df_original = pd.read_csv(join(path_dir,\"data\",\"raw\",\"test.csv\"))\n",
    "passenger_ids = df_original[\"PassengerId\"]\n",
    "# === T·∫°o file submission ===\n",
    "X_test = df_test.copy()\n",
    "if 'Survived' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['Survived'])\n",
    "\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': passenger_ids,  # ƒë·∫£m b·∫£o test c√≥ c·ªôt n√†y\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "\n",
    "sub_dir = join(path_dir, \"notebook\", \"model\", \"gradient_boosting\", \"submissions\")\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "submission_path = join(sub_dir, \"submission_gb_scaledData_tuned.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"üì§ Submission file saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba212e9",
   "metadata": {},
   "source": [
    "# The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
