{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd250f2",
   "metadata": {},
   "source": [
    "## Multivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d545c3",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74228f6",
   "metadata": {},
   "source": [
    "Multivariate analysis is the process to find the relationship between three or more features in the dataset\n",
    "\n",
    "**Visual Exploration**\n",
    "- 3D scatterplots of predictors colored by outcome.\n",
    "- Pairplot (all predictors, hue = outcome) to spot separation patterns.\n",
    "- Dimensionality reduction (PCA, t-SNE) → project many predictors into 2D/3D and color by outcome.\n",
    "\n",
    "**Statistical Tests**\n",
    "- MANOVA → test whether multiple predictors jointly differ across outcome groups.\n",
    "- Logistic regression / discriminant analysis with multiple predictors → check significance of combined effects.\n",
    "\n",
    "**Model-Based Exploration**\n",
    "- Decision tree / random forest → capture non-linear interactions, check feature importance.\n",
    "- Add interaction terms (e.g. Glucose × BMI × Insulin) in regression to test joint influence.\n",
    "\n",
    "**Interpretation**\n",
    "- Do combinations of predictors improve separation between outcome groups?\n",
    "- Which predictors interact to give stronger signals than alone?\n",
    "- Are there hidden clusters in higher dimensions aligned with the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299af4f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3950c8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Separate predictors and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3cb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "           \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
    "\n",
    "df = pd.read_csv('pima-indians-diabetes.data.csv', names=columns)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "X = df.drop(columns=[\"Outcome\"])\n",
    "y = df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b2f27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multivariate Analysis without Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72754f4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855f3fd",
   "metadata": {},
   "source": [
    "This step checks how strongly pairs of features are related to each other using correlaion and covariance.\n",
    "\n",
    "If two features show very high correlation (correlation >= 0.8), they carry almost the same information. Keeping both can cause multicollinearity, which confuses certain models (like regression), makes coefficients unstable, slows training, and can even reduce prediction accuracy. In such cases, one predictor may be removed or combined with the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43b313",
   "metadata": {},
   "source": [
    "#### Detecting high correlation from pairs of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correlation matrix to identify strongly related features\n",
    "corr_matrix = df.corr()\n",
    "col_features = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "           \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "high_corr_list = []\n",
    "for row in col_features:\n",
    "    for col in col_features:\n",
    "        if row == col:\n",
    "            continue\n",
    "        if abs(corr_matrix[row][col]) > 0.8:\n",
    "            high_corr_list.append(f\"{row} - {col}\")\n",
    "print(f\"High correlation: {high_corr_list if len(high_corr_list) > 0 else \"None\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb461f58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Visualization correlation from pairs of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba815ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483136b-d640-4cce-a1db-93a6dacde8be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Detecting high covariance from pairs of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95399b06-0810-4e0c-96a5-9904e7f7825c",
   "metadata": {},
   "source": [
    "Covariance shows whether two variables increase/decrease together, but its magnitude depends on the units of the variables. Unlike correlation, there is no universal threshold for “high” covariance. Therefore, correlation is usually preferred in EDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395f5c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01cc86",
   "metadata": {},
   "source": [
    "There are no pairs of features that have high correlation in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a9696",
   "metadata": {},
   "source": [
    "### Multivariate Analysis with Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce1e00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c22d99",
   "metadata": {},
   "source": [
    "Now we check the features' relationship with the target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36482103",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82adcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8189966",
   "metadata": {},
   "source": [
    "not done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd216568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00d094",
   "metadata": {},
   "source": [
    "not done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ce044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f5981",
   "metadata": {},
   "source": [
    "not done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f78ae-cffc-4089-b296-e43a7e6f054b",
   "metadata": {},
   "source": [
    "## The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
