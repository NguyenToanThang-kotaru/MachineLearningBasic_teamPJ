{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8ee849",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6acea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b54768",
   "metadata": {},
   "source": [
    "### Load train.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbca1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load training data.\n"
     ]
    }
   ],
   "source": [
    "# titanic = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "titanic = pd.read_csv('../input/train.csv')\n",
    "df = titanic.copy()\n",
    "test_dataset = pd.read_csv('../input/test.csv')\n",
    "df_test = test_dataset.copy()\n",
    "print(\"Successfully load training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f55b3",
   "metadata": {},
   "source": [
    "## Handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407e5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "master = df['Name'].str.contains(r',\\s*Master.', regex=True)\n",
    "df_master = df[master].copy()\n",
    "\n",
    "mean_age = df['Age'].mean()\n",
    "mean_age_master = df_master['Age'].mean()\n",
    "\n",
    "df_master['Age'] = df_master['Age'].fillna(mean_age_master)\n",
    "df[master] = df_master\n",
    "\n",
    "df['Age'] = df['Age'].fillna(mean_age)\n",
    "df_test['Age'] = df_test['Age'].fillna(mean_age)\n",
    "\n",
    "# Cabin\n",
    "df = df.drop(['Cabin'], axis=1)\n",
    "df_test = df_test.drop(['Cabin'], axis=1)\n",
    "\n",
    "# Embarked and Fare\n",
    "df['Embarked'] = df['Embarked'].fillna(\"S\")\n",
    "df_test['Embarked'] = df_test['Embarked'].fillna(\"S\")\n",
    "\n",
    "fare_mean = df['Fare'].mean()\n",
    "df_test['Fare'] = df_test['Fare'].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1de16",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416a51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age_bin\n",
    "df['Age_bin'] = pd.cut(df['Age'], bins=[-0.1, 12, 19, 26, 33, 46, 61, 100], labels=False)\n",
    "df['Age_bin'] = df['Age_bin'].astype('category')\n",
    "df_test['Age_bin'] = pd.cut(df_test['Age'], bins=[-0.1, 12, 19, 26, 33, 46, 61, 100], labels=False)\n",
    "df_test['Age_bin'] = df_test['Age_bin'].astype('category')\n",
    "\n",
    "# Fare_bin\n",
    "df['Fare_bin'] = pd.cut(df['Fare'], bins=[0, 7, 8, 10, 14.45, 20, 31, 50, 100, 1000000], labels=False)\n",
    "df_test['Fare_bin'] = pd.cut(df_test['Fare'], bins=[0, 7, 8, 10, 14.45, 20, 31, 50, 100, 1000000], labels=False)\n",
    "\n",
    "missing_fare_bin = df[df['Fare_bin'].isnull() & (df['Fare'] == 0.0)]\n",
    "df.loc[missing_fare_bin.index, 'Fare_bin'] = 0\n",
    "\n",
    "missing_fare_bin_test = df_test[df_test['Fare_bin'].isnull() & (df_test['Fare'] == 0.0)]\n",
    "df_test.loc[missing_fare_bin_test.index, 'Fare_bin'] = 0\n",
    "\n",
    "df['Fare_bin'] = df['Fare_bin'].astype('category')\n",
    "df_test['Fare_bin'] = df_test['Fare_bin'].astype('category')\n",
    "\n",
    "# FamilySize\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "\n",
    "# FamilyGroup\n",
    "df['FamilyGroup'] = pd.cut(df['FamilySize'], bins=[0, 1, 4, 7, 20], labels=False)\n",
    "df['FamilyGroup'] = df['FamilyGroup'].astype('category')\n",
    "\n",
    "df_test['FamilyGroup'] = pd.cut(df_test['FamilySize'], bins=[0, 1, 4, 7, 20], labels=False)\n",
    "df_test['FamilyGroup'] = df_test['FamilyGroup'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a655e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  891 non-null    int64   \n",
      " 1   Survived     891 non-null    int64   \n",
      " 2   Pclass       891 non-null    int64   \n",
      " 3   Name         891 non-null    object  \n",
      " 4   Sex          891 non-null    object  \n",
      " 5   Age          891 non-null    float64 \n",
      " 6   SibSp        891 non-null    int64   \n",
      " 7   Parch        891 non-null    int64   \n",
      " 8   Ticket       891 non-null    object  \n",
      " 9   Fare         891 non-null    float64 \n",
      " 10  Embarked     891 non-null    object  \n",
      " 11  Age_bin      891 non-null    category\n",
      " 12  Fare_bin     891 non-null    category\n",
      " 13  FamilySize   891 non-null    int64   \n",
      " 14  FamilyGroup  891 non-null    category\n",
      "dtypes: category(3), float64(2), int64(6), object(4)\n",
      "memory usage: 87.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  418 non-null    int64   \n",
      " 1   Pclass       418 non-null    int64   \n",
      " 2   Name         418 non-null    object  \n",
      " 3   Sex          418 non-null    object  \n",
      " 4   Age          418 non-null    float64 \n",
      " 5   SibSp        418 non-null    int64   \n",
      " 6   Parch        418 non-null    int64   \n",
      " 7   Ticket       418 non-null    object  \n",
      " 8   Fare         418 non-null    float64 \n",
      " 9   Embarked     418 non-null    object  \n",
      " 10  Age_bin      418 non-null    category\n",
      " 11  Fare_bin     418 non-null    category\n",
      " 12  FamilySize   418 non-null    int64   \n",
      " 13  FamilyGroup  418 non-null    category\n",
      "dtypes: category(3), float64(2), int64(5), object(4)\n",
      "memory usage: 38.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff619a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   Survived    891 non-null    int64   \n",
      " 1   Pclass      891 non-null    int64   \n",
      " 2   Sex         891 non-null    int64   \n",
      " 3   Age         891 non-null    float64 \n",
      " 4   Fare        891 non-null    float64 \n",
      " 5   Embarked    891 non-null    int64   \n",
      " 6   Age_bin     891 non-null    category\n",
      " 7   Fare_bin    891 non-null    category\n",
      " 8   FamilySize  891 non-null    int64   \n",
      "dtypes: category(2), float64(2), int64(5)\n",
      "memory usage: 51.3 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   Pclass      418 non-null    int64   \n",
      " 1   Sex         418 non-null    int64   \n",
      " 2   Age         418 non-null    float64 \n",
      " 3   Fare        418 non-null    float64 \n",
      " 4   Embarked    418 non-null    int64   \n",
      " 5   Age_bin     418 non-null    category\n",
      " 6   Fare_bin    418 non-null    category\n",
      " 7   FamilySize  418 non-null    int64   \n",
      "dtypes: category(2), float64(2), int64(4)\n",
      "memory usage: 21.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'FamilyGroup', 'SibSp', 'Parch'], axis=1) # remove these feature because 1. not analyze it yet and 2. have other things to show that features (Pclass instead of fare and cabin and ticket)\n",
    "df_test = df_test.drop(['PassengerId', 'Name', 'Ticket', 'FamilyGroup', 'SibSp', 'Parch'], axis=1)\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df_test['Sex'] = df_test['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "df['Embarked'] = df['Embarked'].map({'C': 0, 'S': 1, 'Q': 2})\n",
    "df_test['Embarked'] = df_test['Embarked'].map({'C': 0, 'S': 1, 'Q': 2})\n",
    "df.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5968eed",
   "metadata": {},
   "source": [
    "## Model (AI generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a8a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Validation Accuracy = 0.8097\n",
      "Decision Tree: Validation Accuracy = 0.7799\n",
      "Random Forest: Validation Accuracy = 0.8134\n",
      "Gradient Boosting: Validation Accuracy = 0.8022\n",
      "AdaBoost: Validation Accuracy = 0.7985\n",
      "SVC: Validation Accuracy = 0.6567\n",
      "KNN: Validation Accuracy = 0.7052\n",
      "Naive Bayes: Validation Accuracy = 0.7799\n",
      "\n",
      "Best model: Random Forest with accuracy 0.8134\n",
      "Validation Accuracy: 0.8134\n",
      "Model saved to feature_titanic_random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "df_input = df.drop(['Survived'], axis=1)\n",
    "df_outcome = df['Survived']\n",
    "\n",
    "# Prepare input and output\n",
    "X = df_input\n",
    "y = df_outcome.astype(int)  # Ensure target is integer\n",
    "\n",
    "# Split data\n",
    "# Try multiple models and compare their performance\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"SVC\": SVC(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"{name}: Validation Accuracy = {acc:.4f}\")\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nBest model: {best_model_name} with accuracy {results[best_model_name]:.4f}\")\n",
    "\n",
    "# Use the best model for further prediction\n",
    "model = models[best_model_name]\n",
    "\n",
    "# Train model\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save model to file\n",
    "joblib.dump(model, \"feature_titanic_random_forest_model.joblib\")\n",
    "print(\"Model saved to feature_titanic_random_forest_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc47d84",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212815db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best parameters: {'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 10}\n",
      "Best CV score: 0.8345\n",
      "Tuned Model Validation Accuracy: 0.8284\n",
      "Tuned model saved as feature_titanic_tuned_random_forest_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Add these cells after your model selection code\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Assuming 'model' is the best model from your selection\n",
    "best_model = model\n",
    "\n",
    "# Define param_grids for each possible model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 1.0]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    \"Naive Bayes\": {}  # No hyperparameters to tune for GaussianNB\n",
    "}\n",
    "\n",
    "# Get the param_grid for the best model\n",
    "model_name = best_model_name  # From your earlier code\n",
    "if model_name in param_grids:\n",
    "    param_grid = param_grids[model_name]\n",
    "    if param_grid:  # Only tune if there are params\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            estimator=best_model,\n",
    "            param_distributions=param_grid,\n",
    "            cv=10,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        tuned_model = grid_search.best_estimator_\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    else:\n",
    "        tuned_model = best_model  # No tuning needed\n",
    "        print(\"No hyperparameters to tune for this model.\")\n",
    "else:\n",
    "    tuned_model = best_model\n",
    "    print(\"Param grid not defined for this model.\")\n",
    "\n",
    "# Evaluate tuned model\n",
    "y_pred_tuned = tuned_model.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(f\"Tuned Model Validation Accuracy: {accuracy_tuned:.4f}\")\n",
    "\n",
    "# Save tuned model\n",
    "joblib.dump(tuned_model, f\"feature_titanic_tuned_{model_name.lower().replace(' ', '_')}_model.joblib\")\n",
    "print(f\"Tuned model saved as feature_titanic_tuned_{model_name.lower().replace(' ', '_')}_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7aa29",
   "metadata": {},
   "source": [
    "## Evaluate performance (AI Generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0e9563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[136  21]\n",
      " [ 29  82]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       157\n",
      "           1       0.80      0.74      0.77       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.80      0.81       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate model performance on test set\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac7841",
   "metadata": {},
   "source": [
    "## Prediction on test sets (AI Generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7c2060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction file saved as feature_submit_prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop columns not used in training\n",
    "X_submit = df_test\n",
    "\n",
    "submit_pred = model.predict(X_submit)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_dataset['PassengerId'],\n",
    "    'Survived': submit_pred.astype(int)\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "submission.to_csv('feature_submit_prediction.csv', index=False)\n",
    "print(\"Prediction file saved as feature_submit_prediction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
