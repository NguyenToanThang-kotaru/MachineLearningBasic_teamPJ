{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a8ca84fe",
      "metadata": {},
      "source": [
        "# Titanic - Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "128d7b69",
      "metadata": {},
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cf1faf",
      "metadata": {},
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019628c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-05T15:36:17.074902Z",
          "iopub.status.busy": "2025-10-05T15:36:17.074479Z",
          "iopub.status.idle": "2025-10-05T15:36:17.080831Z",
          "shell.execute_reply": "2025-10-05T15:36:17.079627Z",
          "shell.execute_reply.started": "2025-10-05T15:36:17.074871Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fecad07",
      "metadata": {},
      "source": [
        "### Load train.csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49303d7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-05T15:36:17.103688Z",
          "iopub.status.busy": "2025-10-05T15:36:17.103211Z",
          "iopub.status.idle": "2025-10-05T15:36:17.124336Z",
          "shell.execute_reply": "2025-10-05T15:36:17.123445Z",
          "shell.execute_reply.started": "2025-10-05T15:36:17.103652Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully load training data.\n"
          ]
        }
      ],
      "source": [
        "path_dir = os.path.join(\"..\", \"..\", \"data\", \"raw\")\n",
        "titanic = pd.read_csv(os.path.join(path_dir, \"train.csv\"))\n",
        "df = titanic.copy()\n",
        "test_dataset = pd.read_csv(os.path.join(path_dir, \"test.csv\"))\n",
        "df_test = test_dataset.copy()\n",
        "print(\"Successfully load training data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15edd9cb",
      "metadata": {},
      "source": [
        "## Handle missing value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b76fe6",
      "metadata": {},
      "source": [
        "We need to find solutions to handle missing value.\n",
        "From the output detecting missing value, here's the proportion of missing value for `Age`, `Cabin`, and `Embarked` in train dataset:\n",
        "\n",
        "- Age: 19.87%\n",
        "- Cabin: 77.10%\n",
        "- Embarked: 0.22%\n",
        "\n",
        "For test dataset, here's the proportion of missing value for `Age`, `Cabin`, and `Fare`:\n",
        "- Age: 20.57%\n",
        "- Cabin: 78.23%\n",
        "- Fare: 0.24%\n",
        "\n",
        "For `Cabin` features, although the missing value percentage are pretty high, it could be a good information to show passenger's room level, which is a really crucial detail related to survivability. Furthermore, we can base on that information to know if the passengers stayed at the front part (bow) of the Titanic, which is the part of the ship that sank first.\n",
        "\n",
        "For `Age` features, it could related to the survivability, as children and elderly usually be prioritized.\n",
        "\n",
        "For `Embarked` features, it could related to passenger's room level (passengers go on the ship first might have room that are in higher level).\n",
        "\n",
        "Because of that, I think that we should not remove these features. We need to handle value instead.\n",
        "\n",
        "For testing dataset, we also have missing value in `Fare` feature. We will handle it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8068ed40",
      "metadata": {},
      "source": [
        "### Handle missing age value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac3aadd",
      "metadata": {},
      "source": [
        "Honorific title inside passengers' name could tell us a little about their age.\n",
        "\n",
        "At first, we splited value `Age` into 5 main groups: Mr, Mrs, Master, Miss, and other in order to not only impute missing values but also capture potential age-related patterns.\n",
        "\n",
        "But after looking at survivability rate of each group, we decided not to complicate things and just impute missing value with median age of the whole dataset. Except for `Master` group, we will impute missing value with median age of this group as title \"Master\" is only for people under 12."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3f10b214",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-05T15:36:18.356890Z",
          "iopub.status.busy": "2025-10-05T15:36:18.356580Z",
          "iopub.status.idle": "2025-10-05T15:36:18.391541Z",
          "shell.execute_reply": "2025-10-05T15:36:18.390740Z",
          "shell.execute_reply.started": "2025-10-05T15:36:18.356862Z"
        }
      },
      "outputs": [],
      "source": [
        "master = df['Name'].str.contains(r',\\s*Master.', regex=True)\n",
        "df_master = df[master].copy()\n",
        "\n",
        "mean_age = df['Age'].mean()\n",
        "mean_age_master = df_master['Age'].mean()\n",
        "\n",
        "df_master['Age'] = df_master['Age'].fillna(mean_age_master)\n",
        "df[master] = df_master\n",
        "\n",
        "df['Age'] = df['Age'].fillna(mean_age)\n",
        "df_test['Age'] = df_test['Age'].fillna(mean_age)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138b614b",
      "metadata": {},
      "source": [
        "### Handle missing values from Cabin, Embarked (train dataset) and Fare (test dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f7e6e0",
      "metadata": {},
      "source": [
        "Perhaps the only features that we could use to guess people's cabin is Ticket number, but since there are no ticket number system, we could not conclude anything from that.\n",
        "\n",
        "At first, I thought it would be possible to fill missing `Cabin` value by looking at passengers' ticket class, fare, and embarked point, but after some research, I found out that there is no clear relationship between these features and `Cabin` value.\n",
        "\n",
        "Therefore, I will just remove the `Cabin` feature, as it has too many missing values and we could not find a way to fill them.\n",
        "\n",
        "As for Embarked value, I will choose \"S\" to fill that, as the primary embarked point was Southampton (Titanic trip started from there)\n",
        "\n",
        "As for Fare value in testing dataset, I will fill it with median of Fare value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "683fbf1f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-05T15:36:18.392728Z",
          "iopub.status.busy": "2025-10-05T15:36:18.392433Z",
          "iopub.status.idle": "2025-10-05T15:36:18.399257Z",
          "shell.execute_reply": "2025-10-05T15:36:18.398462Z",
          "shell.execute_reply.started": "2025-10-05T15:36:18.392703Z"
        }
      },
      "outputs": [],
      "source": [
        "df = df.drop(['Cabin'], axis=1)\n",
        "df_test = df_test.drop(['Cabin'], axis=1)\n",
        "\n",
        "df['Embarked'] = df['Embarked'].fillna(\"S\")\n",
        "df_test['Embarked'] = df_test['Embarked'].fillna(\"S\")\n",
        "\n",
        "fare_mean = df['Fare'].mean()\n",
        "df_test['Fare'] = df_test['Fare'].fillna(fare_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90abbc11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-05T15:36:18.401072Z",
          "iopub.status.busy": "2025-10-05T15:36:18.400467Z",
          "iopub.status.idle": "2025-10-05T15:36:18.422622Z",
          "shell.execute_reply": "2025-10-05T15:36:18.421632Z",
          "shell.execute_reply.started": "2025-10-05T15:36:18.401043Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Percentage of missing values =====\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Age         0.0\n",
              "Embarked    0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"===== Quantity of missing values =====\")\n",
        "df[['Age', 'Embarked']].isnull().sum()\n",
        "df_test[['Fare']].isnull().sum()\n",
        "print()\n",
        "print(\"===== Percentage of missing values =====\")\n",
        "df[['Age', 'Embarked']].isnull().sum() / len(df) * 100\n",
        "df_test[['Fare']].isnull().sum() / len(df_test) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeadd225",
      "metadata": {},
      "source": [
        "## Detecting outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6d986a",
      "metadata": {},
      "source": [
        "This section will mainly focus on addressing outlier values in numeric features.\n",
        "\n",
        "Based on the outputs from the boxplot from EDA Analysis, we could see that `Age`, `Fare`, `SibSp`, and `Parch` features have outlier values. However, since `SibSp` and `Parch` features are not continuous (both features have a limited number of unique values), we will not handle outlier values in these two features, as it could affect negatively on the model.\n",
        "\n",
        "To handle outlier values, IQR method is used to find the lower bound and upper bound, then replace outlier values with values within these bounds using techniques such as capping or imputation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9f61c91c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total outliers in Age: 66\n",
            "Total outliers in Fare: 116\n"
          ]
        }
      ],
      "source": [
        "num_cols = ['Age', 'Fare']\n",
        "def detect_outliers_iqr(df, col, factor=1.5):\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = max(Q1 - factor * IQR, 0)  # Age cannot be negative\n",
        "    upper_bound = Q3 + factor * IQR\n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "    # print(f'{col} - Outliers (IQR): {len(outliers)}, Lower: {lower_bound:.2f}, Upper: {upper_bound:.2f}')\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "\n",
        "for col in num_cols:\n",
        "    outliers, lower_bound, upper_bound = detect_outliers_iqr(df, col)\n",
        "    print(f'Total outliers in {col}: {len(outliers)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46a929c7",
      "metadata": {},
      "source": [
        "Base on the outcome, we could see that:\n",
        "- Total outliers in Age: 66\n",
        "- Total outliers in Fare: 116\n",
        "\n",
        "The number of outliers in `Fare` is quite high, we will have to handle it carefully in the next part."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e547dda",
      "metadata": {},
      "source": [
        "## Save file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6422ea",
      "metadata": {},
      "source": [
        "We will save train and test files to use for the future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4662d39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved preprocessed data.\n"
          ]
        }
      ],
      "source": [
        "df.to_csv(os.path.join(path_dir, \"preprocessed\", \"preprocessed_train.csv\"))\n",
        "df_test.to_csv(os.path.join(path_dir, \"preprocessed\", \"preprocessed_test.csv\"))\n",
        "print(\"Successfully saved preprocessed data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d15741",
      "metadata": {},
      "source": [
        "# The end"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
