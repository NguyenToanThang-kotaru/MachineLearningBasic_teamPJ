{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "134ba4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../Titanic project/input/train.csv\")\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71c14b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            137\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          552\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()\n",
    "# X_valid.isnull().sum()\n",
    "# print(X_train)\n",
    "\n",
    "# df[['Age', 'Cabin', 'Embarked']].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55aed3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             40\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          135\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1754567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column  Outlier Count  Lower Bound  Upper Bound  Outlier %\n",
      "0  PassengerId              0      -444.00      1336.00       0.00\n",
      "1       Pclass              0         0.50         4.50       0.00\n",
      "2          Age             11        -6.69        64.81       1.23\n",
      "3        SibSp             46        -1.50         2.50       5.16\n",
      "4        Parch            213         0.00         0.00      23.91\n",
      "5         Fare            116       -26.72        65.63      13.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_outliers_iqr(df, col, factor=1.5):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "# Lấy danh sách các cột số\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Tạo DataFrame để thống kê outlier\n",
    "outlier_summary = []\n",
    "\n",
    "for col in num_cols:\n",
    "    n_outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    outlier_summary.append({\n",
    "        'Column': col,\n",
    "        'Outlier Count': n_outliers,\n",
    "        'Lower Bound': round(lower, 2),\n",
    "        'Upper Bound': round(upper, 2),\n",
    "        'Outlier %': round(n_outliers / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d5aabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_6084\\493155443.py:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_6084\\493155443.py:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def preprocess(df, mean_age=None, mode_embarked=None, fit_encoders=False, encoders=None):\n",
    "#     df = df.copy()\n",
    "\n",
    "#     # Nếu chưa truyền mean/mode, tính từ df (thường là train)\n",
    "#     if mean_age is None:\n",
    "#         mean_age = df['Age'].mean()\n",
    "#     if mode_embarked is None:\n",
    "#         mode_embarked = df['Embarked'].mode()[0]\n",
    "\n",
    "#     # Điền giá trị thiếu\n",
    "#     df['Age'] = df['Age'].fillna(mean_age)\n",
    "#     df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "#     # Xử lý outlier\n",
    "#     df['Age'] = df['Age'].clip(0, 65)\n",
    "#     df['SibSp'] = df['SibSp'].clip(0, 5)\n",
    "#     df['Parch'] = df['Parch'].clip(0, 4)\n",
    "#     df['Fare'] = np.log1p(df['Fare'])\n",
    "\n",
    "#     # --- MÃ HÓA ---\n",
    "\n",
    "#     # 1️Phân nhóm tuổi (Age bins)\n",
    "#     bins = [0, 12, 18, 35, 60, 100]\n",
    "#     labels = ['Child', 'Teen', 'Adult', 'MidAge', 'Senior']\n",
    "#     df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "\n",
    "#     # 2️One-hot encode cho biến phân loại\n",
    "#     df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'AgeGroup'], drop_first=True)\n",
    "#     df = df.drop(['Cabin', 'Age','PassengerId', 'Name', 'Ticket','SibSp', 'Parch'], axis=1)\n",
    "\n",
    "#     return df, mean_age, mode_embarked\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(df, mean_age=None, mode_embarked=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    if mean_age is None:\n",
    "        mean_age = df['Age'].mean()\n",
    "    if mode_embarked is None:\n",
    "        mode_embarked = df['Embarked'].mode()[0]\n",
    "\n",
    "    df['Age'] = df['Age'].fillna(mean_age)\n",
    "    df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Age'] = df['Age'].clip(0,65)\n",
    "    df['SibSp'] = df['SibSp'].clip(0,5)\n",
    "    df['Parch'] = df['Parch'].clip(0,4)\n",
    "    df['Fare'] = np.log1p(df['Fare'])\n",
    "\n",
    "    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(\n",
    "        ['Lady', 'Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    df['Ticket_prefix'] = df['Ticket'].str.extract('([A-Za-z./]+)', expand=False)\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].fillna('NONE')\n",
    "    rare_prefix = df['Ticket_prefix'].value_counts()[df['Ticket_prefix'].value_counts() < 10].index\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].replace(rare_prefix, 'Rare')\n",
    "    df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n",
    "    df['Ticket_number'] = df['Ticket_number'].fillna(0).astype(int)\n",
    "    df['Ticket_number'] = np.log1p(df['Ticket_number'])\n",
    "\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize']==1).astype(int)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Sex','Embarked','Title','Ticket_prefix'], drop_first=False)\n",
    "    df = df.drop(['PassengerId','Cabin','Name','Ticket'], axis=1)\n",
    "\n",
    "    return df, mean_age, mode_embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2bed6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep, mean_age, mode_embarked = preprocess(X_train)\n",
    "X_valid_prep, _, _ = preprocess(X_valid, mean_age, mode_embarked)\n",
    "columns_train = X_train_prep.columns\n",
    "for col in columns_train:\n",
    "    if col not in X_valid_prep.columns:\n",
    "        X_valid_prep[col] = 0\n",
    "X_valid_prep = X_valid_prep[columns_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6961dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass        Age  SibSp  Parch      Fare  Ticket_number  FamilySize  \\\n",
      "692       3  29.807687      0      0  4.051712       7.379008           1   \n",
      "481       2  29.807687      0      0  0.000000      12.387790           1   \n",
      "527       1  29.807687      0      0  5.406181       9.769041           1   \n",
      "855       3  18.000000      0      1  2.336987      12.879252           2   \n",
      "801       2  31.000000      1      1  3.305054      10.371051           3   \n",
      "..      ...        ...    ...    ...       ...            ...         ...   \n",
      "359       3  29.807687      0      0  2.183711      12.709816           1   \n",
      "258       1  35.000000      0      0  6.240917       9.784479           1   \n",
      "736       3  48.000000      1      3  3.566005       8.796188           5   \n",
      "462       1  47.000000      0      0  3.676301      11.620173           1   \n",
      "507       1  29.807687      0      0  3.316003      11.621134           1   \n",
      "\n",
      "     IsAlone  Sex_female  Sex_male  ...  Title_Miss  Title_Mr  Title_Mrs  \\\n",
      "692        1       False      True  ...       False      True      False   \n",
      "481        1       False      True  ...       False      True      False   \n",
      "527        1       False      True  ...       False      True      False   \n",
      "855        0        True     False  ...       False     False       True   \n",
      "801        0        True     False  ...       False     False       True   \n",
      "..       ...         ...       ...  ...         ...       ...        ...   \n",
      "359        1        True     False  ...        True     False      False   \n",
      "258        1        True     False  ...        True     False      False   \n",
      "736        0        True     False  ...       False     False       True   \n",
      "462        1       False      True  ...       False      True      False   \n",
      "507        1       False      True  ...       False      True      False   \n",
      "\n",
      "     Title_Rare  Ticket_prefix_A/  Ticket_prefix_C.A.  Ticket_prefix_NONE  \\\n",
      "692       False             False               False                True   \n",
      "481       False             False               False                True   \n",
      "527       False             False               False               False   \n",
      "855       False             False               False                True   \n",
      "801       False             False                True               False   \n",
      "..          ...               ...                 ...                 ...   \n",
      "359       False             False               False                True   \n",
      "258       False             False               False               False   \n",
      "736       False             False               False               False   \n",
      "462       False             False               False                True   \n",
      "507       False             False               False                True   \n",
      "\n",
      "     Ticket_prefix_PC  Ticket_prefix_Rare  Ticket_prefix_STON/O  \n",
      "692             False               False                 False  \n",
      "481             False               False                 False  \n",
      "527              True               False                 False  \n",
      "855             False               False                 False  \n",
      "801             False               False                 False  \n",
      "..                ...                 ...                   ...  \n",
      "359             False               False                 False  \n",
      "258              True               False                 False  \n",
      "736             False                True                 False  \n",
      "462             False               False                 False  \n",
      "507             False               False                 False  \n",
      "\n",
      "[712 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "851000e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       110\n",
      "           1       0.83      0.75      0.79        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.83      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "📘 Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       110\n",
      "           1       0.68      0.65      0.67        69\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.73      0.73      0.73       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "📘 Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "📘 KNN Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.82       110\n",
      "           1       0.73      0.59      0.66        69\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.75      0.73      0.74       179\n",
      "weighted avg       0.76      0.76      0.75       179\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:21:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Logistic Regression  0.843575   0.825397  0.753623  0.787879\n",
      "2        Random Forest  0.815642   0.772727  0.739130  0.755556\n",
      "4              XGBoost  0.815642   0.772727  0.739130  0.755556\n",
      "1        Decision Tree  0.748603   0.681818  0.652174  0.666667\n",
      "3                  KNN  0.759777   0.732143  0.594203  0.656000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# --- Tách dữ liệu nếu chưa có ---\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Danh sách mô hình ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# --- Huấn luyện và đánh giá ---\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_prep, y_train)\n",
    "    preds = model.predict(X_valid_prep)\n",
    "    \n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    prec = precision_score(y_valid, preds)\n",
    "    rec = recall_score(y_valid, preds)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "    \n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "    print(f\"📘 {name} Report:\\n{classification_report(y_valid, preds)}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# --- Tổng hợp kết quả ---\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "results_df = results_df.sort_values(by=\"F1-Score\", ascending=False)\n",
    "# print(\"\\n📊 Tổng hợp kết quả:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57b66431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'solver': 'saga', 'penalty': 'l1', 'l1_ratio': np.float64(0.5555555555555556), 'class_weight': 'balanced', 'C': np.float64(6.158482110660261)}\n",
      "✅ Best F1-score (CV): 0.7572208490349419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       110\n",
      "           1       0.76      0.83      0.79        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.83      0.83       179\n",
      "weighted avg       0.84      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "logreg = LogisticRegression(random_state=42, max_iter=5000)\n",
    "\n",
    "# --- Grid / distribution cho RandomizedSearch ---\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 3, 20),          # thử C từ 0.001 → 1000\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'], # loại regularization\n",
    "    'solver': ['saga'],                    # saga hỗ trợ l1/l2/elasticnet\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'l1_ratio': np.linspace(0,1,10)       # chỉ dùng nếu penalty='elasticnet'\n",
    "}\n",
    "\n",
    "# --- RandomizedSearchCV ---\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='f1',       # tối ưu theo F1\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# --- Train ---\n",
    "random_search_lr.fit(X_train_prep, y_train)\n",
    "\n",
    "# --- Kết quả ---\n",
    "print(\"✅ Best Params:\", random_search_lr.best_params_)\n",
    "print(\"✅ Best F1-score (CV):\", random_search_lr.best_score_)\n",
    "\n",
    "# --- Validation ---\n",
    "best_lr = random_search_lr.best_estimator_\n",
    "y_pred = best_lr.predict(X_valid_prep)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "180cc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"../Titanic project/input/test.csv\")\n",
    "\n",
    "# 2️⃣ Preprocess train\n",
    "Df_Final, mean_age, mode_embarked = preprocess(X)\n",
    "\n",
    "# 3️⃣ Preprocess test (dùng mean và mode từ train)\n",
    "X_test_prep, _, _ = preprocess(test_df, mean_age, mode_embarked)\n",
    "\n",
    "# 4️⃣ Đồng bộ cột\n",
    "for col in columns_train:\n",
    "    if col not in X_test_prep.columns:\n",
    "        X_test_prep[col] = 0\n",
    "X_test_prep = X_test_prep[columns_train]\n",
    "\n",
    "best_params = random_search_lr.best_params_\n",
    "best_lr_final =  LogisticRegression(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    ")\n",
    "best_lr_final.fit(Df_Final, y)\n",
    "# 4️⃣ Dự đoán trên test set đã preprocess\n",
    "y_test_pred = best_lr_final.predict(X_test_prep)\n",
    "\n",
    "# 5️⃣ Xuất file submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
