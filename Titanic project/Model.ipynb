{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "134ba4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"../Titanic project/input/train.csv\")\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "# print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71c14b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            137\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          552\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()\n",
    "# X_valid.isnull().sum()\n",
    "# print(X_train)\n",
    "\n",
    "# df[['Age', 'Cabin', 'Embarked']].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55aed3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             40\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          135\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1754567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Column  Outlier Count  Lower Bound  Upper Bound  Outlier %\n",
      "0  PassengerId              0      -444.00      1336.00       0.00\n",
      "1       Pclass              0         0.50         4.50       0.00\n",
      "2          Age             11        -6.69        64.81       1.23\n",
      "3        SibSp             46        -1.50         2.50       5.16\n",
      "4        Parch            213         0.00         0.00      23.91\n",
      "5         Fare            116       -26.72        65.63      13.02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_outliers_iqr(df, col, factor=1.5):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "# L·∫•y danh s√°ch c√°c c·ªôt s·ªë\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# T·∫°o DataFrame ƒë·ªÉ th·ªëng k√™ outlier\n",
    "outlier_summary = []\n",
    "\n",
    "for col in num_cols:\n",
    "    n_outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    outlier_summary.append({\n",
    "        'Column': col,\n",
    "        'Outlier Count': n_outliers,\n",
    "        'Lower Bound': round(lower, 2),\n",
    "        'Upper Bound': round(upper, 2),\n",
    "        'Outlier %': round(n_outliers / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d5aabc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_6084\\493155443.py:56: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_6084\\493155443.py:67: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def preprocess(df, mean_age=None, mode_embarked=None, fit_encoders=False, encoders=None):\n",
    "#     df = df.copy()\n",
    "\n",
    "#     # N·∫øu ch∆∞a truy·ªÅn mean/mode, t√≠nh t·ª´ df (th∆∞·ªùng l√† train)\n",
    "#     if mean_age is None:\n",
    "#         mean_age = df['Age'].mean()\n",
    "#     if mode_embarked is None:\n",
    "#         mode_embarked = df['Embarked'].mode()[0]\n",
    "\n",
    "#     # ƒêi·ªÅn gi√° tr·ªã thi·∫øu\n",
    "#     df['Age'] = df['Age'].fillna(mean_age)\n",
    "#     df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "#     # X·ª≠ l√Ω outlier\n",
    "#     df['Age'] = df['Age'].clip(0, 65)\n",
    "#     df['SibSp'] = df['SibSp'].clip(0, 5)\n",
    "#     df['Parch'] = df['Parch'].clip(0, 4)\n",
    "#     df['Fare'] = np.log1p(df['Fare'])\n",
    "\n",
    "#     # --- M√É H√ìA ---\n",
    "\n",
    "#     # 1Ô∏èPh√¢n nh√≥m tu·ªïi (Age bins)\n",
    "#     bins = [0, 12, 18, 35, 60, 100]\n",
    "#     labels = ['Child', 'Teen', 'Adult', 'MidAge', 'Senior']\n",
    "#     df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "\n",
    "#     # 2Ô∏èOne-hot encode cho bi·∫øn ph√¢n lo·∫°i\n",
    "#     df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'AgeGroup'], drop_first=True)\n",
    "#     df = df.drop(['Cabin', 'Age','PassengerId', 'Name', 'Ticket','SibSp', 'Parch'], axis=1)\n",
    "\n",
    "#     return df, mean_age, mode_embarked\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(df, mean_age=None, mode_embarked=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    if mean_age is None:\n",
    "        mean_age = df['Age'].mean()\n",
    "    if mode_embarked is None:\n",
    "        mode_embarked = df['Embarked'].mode()[0]\n",
    "\n",
    "    df['Age'] = df['Age'].fillna(mean_age)\n",
    "    df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Age'] = df['Age'].clip(0,65)\n",
    "    df['SibSp'] = df['SibSp'].clip(0,5)\n",
    "    df['Parch'] = df['Parch'].clip(0,4)\n",
    "    df['Fare'] = np.log1p(df['Fare'])\n",
    "\n",
    "    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(\n",
    "        ['Lady', 'Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    df['Ticket_prefix'] = df['Ticket'].str.extract('([A-Za-z./]+)', expand=False)\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].fillna('NONE')\n",
    "    rare_prefix = df['Ticket_prefix'].value_counts()[df['Ticket_prefix'].value_counts() < 10].index\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].replace(rare_prefix, 'Rare')\n",
    "    df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n",
    "    df['Ticket_number'] = df['Ticket_number'].fillna(0).astype(int)\n",
    "    df['Ticket_number'] = np.log1p(df['Ticket_number'])\n",
    "\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize']==1).astype(int)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Sex','Embarked','Title','Ticket_prefix'], drop_first=False)\n",
    "    df = df.drop(['PassengerId','Cabin','Name','Ticket'], axis=1)\n",
    "\n",
    "    return df, mean_age, mode_embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2bed6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep, mean_age, mode_embarked = preprocess(X_train)\n",
    "X_valid_prep, _, _ = preprocess(X_valid, mean_age, mode_embarked)\n",
    "columns_train = X_train_prep.columns\n",
    "for col in columns_train:\n",
    "    if col not in X_valid_prep.columns:\n",
    "        X_valid_prep[col] = 0\n",
    "X_valid_prep = X_valid_prep[columns_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6961dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass        Age  SibSp  Parch      Fare  Ticket_number  FamilySize  \\\n",
      "692       3  29.807687      0      0  4.051712       7.379008           1   \n",
      "481       2  29.807687      0      0  0.000000      12.387790           1   \n",
      "527       1  29.807687      0      0  5.406181       9.769041           1   \n",
      "855       3  18.000000      0      1  2.336987      12.879252           2   \n",
      "801       2  31.000000      1      1  3.305054      10.371051           3   \n",
      "..      ...        ...    ...    ...       ...            ...         ...   \n",
      "359       3  29.807687      0      0  2.183711      12.709816           1   \n",
      "258       1  35.000000      0      0  6.240917       9.784479           1   \n",
      "736       3  48.000000      1      3  3.566005       8.796188           5   \n",
      "462       1  47.000000      0      0  3.676301      11.620173           1   \n",
      "507       1  29.807687      0      0  3.316003      11.621134           1   \n",
      "\n",
      "     IsAlone  Sex_female  Sex_male  ...  Title_Miss  Title_Mr  Title_Mrs  \\\n",
      "692        1       False      True  ...       False      True      False   \n",
      "481        1       False      True  ...       False      True      False   \n",
      "527        1       False      True  ...       False      True      False   \n",
      "855        0        True     False  ...       False     False       True   \n",
      "801        0        True     False  ...       False     False       True   \n",
      "..       ...         ...       ...  ...         ...       ...        ...   \n",
      "359        1        True     False  ...        True     False      False   \n",
      "258        1        True     False  ...        True     False      False   \n",
      "736        0        True     False  ...       False     False       True   \n",
      "462        1       False      True  ...       False      True      False   \n",
      "507        1       False      True  ...       False      True      False   \n",
      "\n",
      "     Title_Rare  Ticket_prefix_A/  Ticket_prefix_C.A.  Ticket_prefix_NONE  \\\n",
      "692       False             False               False                True   \n",
      "481       False             False               False                True   \n",
      "527       False             False               False               False   \n",
      "855       False             False               False                True   \n",
      "801       False             False                True               False   \n",
      "..          ...               ...                 ...                 ...   \n",
      "359       False             False               False                True   \n",
      "258       False             False               False               False   \n",
      "736       False             False               False               False   \n",
      "462       False             False               False                True   \n",
      "507       False             False               False                True   \n",
      "\n",
      "     Ticket_prefix_PC  Ticket_prefix_Rare  Ticket_prefix_STON/O  \n",
      "692             False               False                 False  \n",
      "481             False               False                 False  \n",
      "527              True               False                 False  \n",
      "855             False               False                 False  \n",
      "801             False               False                 False  \n",
      "..                ...                 ...                   ...  \n",
      "359             False               False                 False  \n",
      "258              True               False                 False  \n",
      "736             False                True                 False  \n",
      "462             False               False                 False  \n",
      "507             False               False                 False  \n",
      "\n",
      "[712 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "851000e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       110\n",
      "           1       0.83      0.75      0.79        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.83      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "üìò Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       110\n",
      "           1       0.68      0.65      0.67        69\n",
      "\n",
      "    accuracy                           0.75       179\n",
      "   macro avg       0.73      0.73      0.73       179\n",
      "weighted avg       0.75      0.75      0.75       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "üìò Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "üìò KNN Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.82       110\n",
      "           1       0.73      0.59      0.66        69\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.75      0.73      0.74       179\n",
      "weighted avg       0.76      0.76      0.75       179\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:21:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       110\n",
      "           1       0.77      0.74      0.76        69\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "------------------------------------------------------------\n",
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Logistic Regression  0.843575   0.825397  0.753623  0.787879\n",
      "2        Random Forest  0.815642   0.772727  0.739130  0.755556\n",
      "4              XGBoost  0.815642   0.772727  0.739130  0.755556\n",
      "1        Decision Tree  0.748603   0.681818  0.652174  0.666667\n",
      "3                  KNN  0.759777   0.732143  0.594203  0.656000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# --- T√°ch d·ªØ li·ªáu n·∫øu ch∆∞a c√≥ ---\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Danh s√°ch m√¥ h√¨nh ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# --- Hu·∫•n luy·ªán v√† ƒë√°nh gi√° ---\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_prep, y_train)\n",
    "    preds = model.predict(X_valid_prep)\n",
    "    \n",
    "    acc = accuracy_score(y_valid, preds)\n",
    "    prec = precision_score(y_valid, preds)\n",
    "    rec = recall_score(y_valid, preds)\n",
    "    f1 = f1_score(y_valid, preds)\n",
    "    \n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "    print(f\"üìò {name} Report:\\n{classification_report(y_valid, preds)}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# --- T·ªïng h·ª£p k·∫øt qu·∫£ ---\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "results_df = results_df.sort_values(by=\"F1-Score\", ascending=False)\n",
    "# print(\"\\nüìä T·ªïng h·ª£p k·∫øt qu·∫£:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57b66431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Params: {'solver': 'saga', 'penalty': 'l1', 'l1_ratio': np.float64(0.5555555555555556), 'class_weight': 'balanced', 'C': np.float64(6.158482110660261)}\n",
      "‚úÖ Best F1-score (CV): 0.7572208490349419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       110\n",
      "           1       0.76      0.83      0.79        69\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.83      0.83       179\n",
      "weighted avg       0.84      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "logreg = LogisticRegression(random_state=42, max_iter=5000)\n",
    "\n",
    "# --- Grid / distribution cho RandomizedSearch ---\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 3, 20),          # th·ª≠ C t·ª´ 0.001 ‚Üí 1000\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'], # lo·∫°i regularization\n",
    "    'solver': ['saga'],                    # saga h·ªó tr·ª£ l1/l2/elasticnet\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'l1_ratio': np.linspace(0,1,10)       # ch·ªâ d√πng n·∫øu penalty='elasticnet'\n",
    "}\n",
    "\n",
    "# --- RandomizedSearchCV ---\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='f1',       # t·ªëi ∆∞u theo F1\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# --- Train ---\n",
    "random_search_lr.fit(X_train_prep, y_train)\n",
    "\n",
    "# --- K·∫øt qu·∫£ ---\n",
    "print(\"‚úÖ Best Params:\", random_search_lr.best_params_)\n",
    "print(\"‚úÖ Best F1-score (CV):\", random_search_lr.best_score_)\n",
    "\n",
    "# --- Validation ---\n",
    "best_lr = random_search_lr.best_estimator_\n",
    "y_pred = best_lr.predict(X_valid_prep)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "180cc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1221: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"../Titanic project/input/test.csv\")\n",
    "\n",
    "# 2Ô∏è‚É£ Preprocess train\n",
    "Df_Final, mean_age, mode_embarked = preprocess(X)\n",
    "\n",
    "# 3Ô∏è‚É£ Preprocess test (d√πng mean v√† mode t·ª´ train)\n",
    "X_test_prep, _, _ = preprocess(test_df, mean_age, mode_embarked)\n",
    "\n",
    "# 4Ô∏è‚É£ ƒê·ªìng b·ªô c·ªôt\n",
    "for col in columns_train:\n",
    "    if col not in X_test_prep.columns:\n",
    "        X_test_prep[col] = 0\n",
    "X_test_prep = X_test_prep[columns_train]\n",
    "\n",
    "best_params = random_search_lr.best_params_\n",
    "best_lr_final =  LogisticRegression(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    ")\n",
    "best_lr_final.fit(Df_Final, y)\n",
    "# 4Ô∏è‚É£ D·ª± ƒëo√°n tr√™n test set ƒë√£ preprocess\n",
    "y_test_pred = best_lr_final.predict(X_test_prep)\n",
    "\n",
    "# 5Ô∏è‚É£ Xu·∫•t file submission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': y_test_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
