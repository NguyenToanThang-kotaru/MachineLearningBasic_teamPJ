{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8654a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_20704\\3113738556.py:30: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
      "C:\\Users\\thien408\\AppData\\Local\\Temp\\ipykernel_20704\\3113738556.py:49: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n",
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  Precision    Recall  F1-Score  Mean_CV_F1\n",
      "4              XGBoost  0.843575   0.810811  0.810811  0.810811    0.736147\n",
      "1        Random Forest  0.837989   0.816901  0.783784  0.800000    0.739594\n",
      "0  Logistic Regression  0.810056   0.777778  0.756757  0.767123    0.760594\n",
      "2        Decision Tree  0.770950   0.732394  0.702703  0.717241    0.716875\n",
      "3                  KNN  0.770950   0.746269  0.675676  0.709220    0.627702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\thien408\\miniconda3\\envs\\lab1\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:16:01] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# ------------------- Preprocess -------------------\n",
    "def preprocess(df, mean_age=None, mode_embarked=None):\n",
    "    df = df.copy()\n",
    "\n",
    "    if mean_age is None:\n",
    "        mean_age = df['Age'].mean()\n",
    "    if mode_embarked is None:\n",
    "        mode_embarked = df['Embarked'].mode()[0]\n",
    "\n",
    "    # df['Age'] = df['Age'].fillna(mean_age)\n",
    "    df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n",
    "    df['Age'] = df['Age'].clip(0,65)\n",
    "    df['SibSp'] = df['SibSp'].clip(0,5)\n",
    "    df['Parch'] = df['Parch'].clip(0,4)\n",
    "    df['Fare'] = np.log1p(df['Fare'])\n",
    "\n",
    "    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(\n",
    "        ['Lady', 'Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Age missing value handling\n",
    "    df_master = df[df['Title'] == 'Master'].copy()\n",
    "    df_master['Age'] = df_master['Age'].fillna(df_master['Age'].mean())\n",
    "    df[df['Title'] == 'Master'] = df_master\n",
    "    \n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    # Endof age missing value handling\n",
    "\n",
    "    df['Ticket_prefix'] = df['Ticket'].str.extract('([A-Za-z./]+)', expand=False)\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].fillna('NONE')\n",
    "    rare_prefix = df['Ticket_prefix'].value_counts()[df['Ticket_prefix'].value_counts() < 10].index\n",
    "    df['Ticket_prefix'] = df['Ticket_prefix'].replace(rare_prefix, 'Rare')\n",
    "    df['Ticket_number'] = df['Ticket'].str.extract('(\\d+)', expand=False)\n",
    "    df['Ticket_number'] = df['Ticket_number'].fillna(0).astype(int)\n",
    "    df['Ticket_number'] = np.log1p(df['Ticket_number'])\n",
    "\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize']==1).astype(int)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Sex','Embarked','Title','Ticket_prefix'], drop_first=False)\n",
    "    df = df.drop(['PassengerId','Cabin','Name','Ticket'], axis=1)\n",
    "\n",
    "    return df, mean_age, mode_embarked\n",
    "\n",
    "# ------------------- Load data -------------------\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "y = train_df['Survived']\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "# X_prep, mean_age, mode_embarked = preprocess(X)\n",
    "\n",
    "\n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, mean_age, mode_embarked = preprocess(X_train_raw)\n",
    "\n",
    "X_valid, _, _ = preprocess(X_valid_raw, mean_age=mean_age, mode_embarked=mode_embarked)\n",
    "\n",
    "# ⚠ Fix cột thiếu ở validation (one-hot)\n",
    "for col in X_train.columns:\n",
    "    if col not in X_valid.columns:\n",
    "        X_valid[col] = 0\n",
    "X_valid = X_valid[X_train.columns]  # sắp xếp theo train\n",
    "# ------------------- Models -------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=3000, solver='saga', penalty='l2'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# ------------------- Train & Evaluate -------------------\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit trên train set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)    \n",
    "\n",
    "\n",
    "    if name == \"XGBoost\":\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        f1_scores = []\n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred_va = model.predict(X_va)\n",
    "            f1_scores.append(f1_score(y_va, y_pred_va))\n",
    "        mean_cv_f1 = np.mean(f1_scores)\n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "        f1_val = f1_score(y_valid, y_pred)    \n",
    "        report = classification_report(y_valid, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": report['1']['precision'],\n",
    "            \"Recall\": report['1']['recall'],\n",
    "            \"F1-Score\": f1_val,\n",
    "            \"Mean_CV_F1\": mean_cv_f1\n",
    "        })\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "        mean_cv_f1 = cv_scores.mean()\n",
    "        acc = accuracy_score(y_valid, y_pred)\n",
    "        f1_val = f1_score(y_valid, y_pred)    \n",
    "        report = classification_report(y_valid, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": report['1']['precision'],\n",
    "            \"Recall\": report['1']['recall'],\n",
    "            \"F1-Score\": f1_val,\n",
    "            \"Mean_CV_F1\": mean_cv_f1\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='F1-Score', ascending=False)\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "def optimize_logistic_regression(X_train, y_train, X_valid, y_valid, use_polynomial=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Optimize Logistic Regression với:\n",
    "    - Scaling\n",
    "    - L1 feature selection\n",
    "    - Polynomial features (tùy chọn)\n",
    "    - GridSearchCV (tuning C, penalty, l1_ratio)\n",
    "    \n",
    "    Trả về dict với kết quả Best Params, CV F1, Validation Accuracy/F1/Precision/Recall\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose: print(\"Step 1: Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "    if verbose: print(\"Step 2: Feature selection (L1 penalty)...\")\n",
    "    selector = SelectFromModel(\n",
    "        LogisticRegression(penalty='l1', solver='saga', C=1, max_iter=5000, random_state=42)\n",
    "    )\n",
    "    selector.fit(X_train_scaled, y_train)\n",
    "    X_train_sel = selector.transform(X_train_scaled)\n",
    "    X_valid_sel = selector.transform(X_valid_scaled)\n",
    "    if verbose: print(f\"Selected {X_train_sel.shape[1]} features from {X_train_scaled.shape[1]} original features.\")\n",
    "\n",
    "    if use_polynomial:\n",
    "        if verbose: print(\"Step 3: Generating Polynomial Features (degree=2)...\")\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "        X_train_poly = poly.fit_transform(X_train_sel)\n",
    "        X_valid_poly = poly.transform(X_valid_sel)\n",
    "        if verbose: print(f\"Polynomial features expanded to {X_train_poly.shape[1]} features.\")\n",
    "    else:\n",
    "        X_train_poly, X_valid_poly = X_train_sel, X_valid_sel\n",
    "\n",
    "    if verbose: print(\"Step 4: GridSearchCV for Logistic Regression hyperparameters...\")\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'l1_ratio': [0, 0.5, 1]  # chỉ dùng khi penalty='elasticnet'\n",
    "    }\n",
    "    logreg = LogisticRegression(max_iter=5000, solver='saga', random_state=42)\n",
    "    grid = GridSearchCV(logreg, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train_poly, y_train)\n",
    "\n",
    "    if verbose: print(\"Step 5: Evaluating on validation set...\")\n",
    "    y_pred = grid.predict(X_valid_poly)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    f1_val = f1_score(y_valid, y_pred)\n",
    "    report = classification_report(y_valid, y_pred, output_dict=True)\n",
    "\n",
    "    results = {\n",
    "        'Best Params': grid.best_params_,\n",
    "        'Best CV F1': grid.best_score_,\n",
    "        'Validation Accuracy': acc,\n",
    "        'Validation F1': f1_val,\n",
    "        'Precision': report['1']['precision'],\n",
    "        'Recall': report['1']['recall']\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Logistic Regression Optimization Results ===\")\n",
    "        for k, v in results.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Giả sử bạn đã preprocess X_train và X_valid\n",
    "# logreg_results = optimize_logistic_regression(X_train, y_train, X_valid, y_valid, use_polynomial=True)\n",
    "# print(logreg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4a196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
